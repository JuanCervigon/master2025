{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1fqHfFdALzEojG1hN2RRVpIbrCmIp_G_Z",
      "authorship_tag": "ABX9TyO7uugYneJyv8WeBdoABkRt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuanCervigon/master2025/blob/main/03_leer_ficheros_de_datos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2F899ebmECY3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Leer ficheros"
      ],
      "metadata": {
        "id": "KBPkKGP3HSPm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Desde mi ordenador\n",
        "\n",
        "Para leer un fichero ubicado en el disco duro del ordenador, primero hay que subirlo al apartado \"Archvos\" del cuaderno de Google. El fichero se puede subir de dos formas\n",
        "\n",
        "\n",
        "* Usando la función `files.upload()`\n",
        "* Drag and drop. Arrastrar y soltar el fichero en el apartado \"Archivos\" de Google Colab.  \n",
        "\n"
      ],
      "metadata": {
        "id": "ED7lINj1ph_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar los modulos necesarios\n",
        "from google.colab import files\n",
        "\n",
        "# Seleccionar manualmente un fichero ubicado en el disco duro\n",
        "fichero = files.upload()\n",
        "\n",
        "# El fichero seleccionado se copia automáticamente en el apartado de Archivos\n",
        "# Además, en la variable 'fichero' se crea un diccionario {key:value} con un unico elemento\n",
        "# key: contiene el nombre del fichero seleccinado\n",
        "# value: contiene los datos del fichero seleccionado\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "sFvENzlS67Wj",
        "outputId": "7310c86c-53bb-4d5c-809a-1f1b9dbf6026"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0ac69505-5978-4a29-9319-d8b8d2765f55\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0ac69505-5978-4a29-9319-d8b8d2765f55\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving borrar.xlsx to borrar.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez que el fichero está en el apartado \"Archvos\" del cuaderno de Google, podemos leerlo como cualquier otro fichero que esté en esa ubicación, sencillamente utilizando la función `pd.read_xx('nombre del fichero')`\n",
        "\n",
        "Si hemos utilizado la opción de seleccionar el fichero, en vez de la opción \"drag and drop\", entonces tenemos el nombre del fichero en la variable que hayamos utilizado en la función `files.upload()` y podemo pasar ese nombre a la función  `pd.read_xx('nombre del fichero')`\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ke80n5pJG7z4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Teclear el nombre del fichero\n",
        "df = pd.read_excel('borrar.xlsx')\n"
      ],
      "metadata": {
        "id": "7Oh7pc3hBLoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "6ouTSiiqgMkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Desde mi Drive"
      ],
      "metadata": {
        "id": "0GfVFVE4hX_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Montar mi drive en colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "w1hTox_Chcu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Leer directamente teniendo en cuenta la ruta dentro de drive\n",
        "\n",
        "ruta = '/content/drive/MyDrive/uc3m/Data/Bicicletas.xlsx'\n",
        "df = pd.read_excel(ruta)\n"
      ],
      "metadata": {
        "id": "iyHGwrs0iR6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Desde una libreria de Python\n",
        "\n",
        "Muchas librerías tienen datasets para hacer práctivas"
      ],
      "metadata": {
        "id": "v7rALehUIKCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Datasets en statsmodels\n",
        "\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Leer el dataset macrodata\n",
        "ejemplo1 = sm.datasets.macrodata.load_pandas().data\n",
        "print(ejemplo1)\n",
        "\n",
        "# Leer el dataset grunfeld\n",
        "ejemplo2 = sm.datasets.grunfeld.load_pandas().data\n",
        "ejemplo2\n",
        "\n",
        "\n",
        "# La lista de todos los dataset está disponible en la documentación de statsmodels"
      ],
      "metadata": {
        "id": "lPZ2zQYaIyR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Desde un repositorio\n",
        "\n",
        "Por ejemplo desde el repositorio GitHub"
      ],
      "metadata": {
        "id": "1daz0EKyHbL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Leer un fichero excel de GitHub\n",
        "\n",
        "# Copiar la url del fichero y añadir una \"r\" delante y \"?raw=true\" al final\n",
        "\n",
        "url=r'https://github.com/JuanCervigon/Cuadernos-INE/blob/main/Conjuntos_de_datos/Mat_div_Provincias_2020.xlsx?raw=true'\n",
        "df=pd.read_excel(url)\n",
        "df\n"
      ],
      "metadata": {
        "id": "WUDuhdfDrUky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GFjSTSLl52q"
      },
      "source": [
        "# Metodos de DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generales"
      ],
      "metadata": {
        "id": "8V2vWpVooksU"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oyAIIovSPkl"
      },
      "source": [
        "# df.shape\n",
        "# df.dtypes\n",
        "# df.describe()\n",
        "# df.head(), tail(), sample()\n",
        "# df.corr()\n",
        "# df.info()\n",
        "# df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dY0AYOWuNaW6"
      },
      "source": [
        "# Hacer Gráficos de los datos\n",
        "\n",
        "# df.plot(kind='scatter',x='tparo',y='pibpc')\n",
        "# df.hist(bins=5,figsize=(20,30))\n",
        "# pd.plotting.scatter_matrix(df, figsize = (10,10),alpha=0.2)\n",
        "\n",
        "# Usando la librería seaborn\n",
        "\n",
        "# sns.countplot()\n",
        "# sns.boxplot()\n",
        "# sns.heatmap(df.corr(), annot=True)\n",
        "# sns.pairplot(df[:])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PopLwLIxOk_-"
      },
      "source": [
        "## Importar datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y406t6skOn7Z"
      },
      "source": [
        "pd.read_csv(filename) # From a CSV file\n",
        "pd.read_table(filename) # From a delimited text file (like TSV)\n",
        "pd.read_excel(filename) # From an Excel file\n",
        "pd.read_sql(query, connection_object) # Reads from a SQL table/database\n",
        "pd.read_json(json_string) # Reads from a JSON formatted string, URL or file.\n",
        "pd.read_html(url) # Parses an html URL, string or file and extracts tables to a list of dataframes\n",
        "pd.read_clipboard() # Takes the contents of your clipboard and passes it to read_table()\n",
        "pd.DataFrame(dict) # From a dict, keys for columns names, values for data as lists"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtMymLI0OzwJ"
      },
      "source": [
        "## Analizar datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaRJ-eSmO4CJ"
      },
      "source": [
        "df.shape() # Prints number of rows and columns in dataframe\n",
        "df.head(n) # Prints first n rows of the DataFrame\n",
        "df.tail(n) # Prints last n rows of the DataFrame\n",
        "df.info() # Index, Datatype and Memory information\n",
        "df.describe() # Summary statistics for numerical columns\n",
        "s.value_counts(dropna=False) # Views unique values and counts\n",
        "df.apply(pd.Series.value_counts) # Unique values and counts for all columns\n",
        "df.describe() # Summary statistics for numerical columns\n",
        "df.mean() # Returns the mean of all columns\n",
        "df.corr() # Returns the correlation between columns in a DataFrame\n",
        "df.count() # Returns the number of non-null values in each DataFrame column\n",
        "df.max() # Returns the highest value in each column\n",
        "df.min() # Returns the lowest value in each column\n",
        "df.median() # Returns the median of each column\n",
        "df.std() # Returns the standard deviation of each column"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZLg_sFePAZg"
      },
      "source": [
        "## Seleccionar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KVO9jubPDMx"
      },
      "source": [
        "df[col] # Returns column with label col as Series\n",
        "df[[col1, col2]] # Returns Columns as a new DataFrame\n",
        "s.iloc[0] # Selection by position (selects first element)\n",
        "s.loc[0] # Selection by index (selects element at index 0)\n",
        "df.iloc[0,:] # First row\n",
        "df.iloc[0,0] # First element of first column\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9BUXCYNblGm"
      },
      "source": [
        "## Limpiar datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNuUd_imPNFb"
      },
      "source": [
        "df.columns = ['a','b','c'] # Renames columns\n",
        "pd.isnull() # Checks for null Values, Returns Boolean Array\n",
        "pd.notnull() # Opposite of s.isnull()\n",
        "df.dropna() # Drops all rows that contain null values\n",
        "df.dropna(axis=1) # Drops all columns that contain null values\n",
        "df.dropna(axis=1,thresh=n) # Drops all rows have have less than n non null values\n",
        "df.fillna(x) # Replaces all null values with x\n",
        "s.fillna(s.mean()) # Replaces all null values with the mean (mean can be replaced with almost any function from the statistics section)\n",
        "s.astype(float) # Converts the datatype of the series to float\n",
        "s.replace(1,'one') # Replaces all values equal to 1 with 'one'\n",
        "s.replace([1,3],['one','three']) # Replaces all 1 with 'one' and 3 with 'three'\n",
        "df.rename(columns=lambda x: x + 1) # Mass renaming of columns\n",
        "df.rename(columns={'old_name': 'new_ name'}) # Selective renaming\n",
        "df.set_index('column_one') # Changes the index\n",
        "df.rename(index=lambda x: x + 1) # Mass renaming of index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3h8UL-vVPRUk"
      },
      "source": [
        "## Filtrar ordenar y agrupar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucg7yk_sPVjX"
      },
      "source": [
        "df[df[col] > 0.5] # Rows where the col column is greater than 0.5\n",
        "df[(df[col] > 0.5) & (df[col] < 0.7)] # Rows where 0.5 < col < 0.7\n",
        "df.sort_values(col1) # Sorts values by col1 in ascending order\n",
        "df.sort_values(col2,ascending=False) # Sorts values by col2 in descending order\n",
        "df.sort_values([col1,col2], ascending=[True,False]) # Sorts values by col1 in ascending order then col2 in descending order\n",
        "df.groupby(col) # Returns a groupby object for values from one column\n",
        "df.groupby([col1,col2]) # Returns a groupby object values from multiple columns\n",
        "df.groupby(col1)[col2].mean() # Returns the mean of the values in col2, grouped by the values in col1 (mean can be replaced with almost any function from the statistics section)\n",
        "df.pivot_table(index=col1, values= col2,col3], aggfunc=mean) # Creates a pivot table that groups by col1 and calculates the mean of col2 and col3\n",
        "df.groupby(col1).agg(np.mean) # Finds the average across all columns for every unique column 1 group\n",
        "df.apply(np.mean) # Applies a function across each column\n",
        "df.apply(np.max, axis=1) # Applies a function across each row"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r8Jk1AMPdQ1"
      },
      "source": [
        "## Unir y combinar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sgv2YiQuPiLr"
      },
      "source": [
        "df1.append(df2) # Adds the rows in df1 to the end of df2 (columns should be identical)\n",
        "pd.concat([df1, df2],axis=1) # Adds the columns in df1 to the end of df2 (rows should be identical)\n",
        "df1.join(df2,on=col1,how='inner') # SQL-style joins the columns in df1 with the columns on df2 where the rows for col have identical values. how can be one of 'left', 'right', 'outer', 'inner'<strong> </strong>\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNtRNjNoPnBo"
      },
      "source": [
        "## Guardar datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmn4nmYHPqF6"
      },
      "source": [
        "df.to_csv(filename) # Writes to a CSV file\n",
        "df.to_excel(filename) # Writes to an Excel file\n",
        "df.to_sql(table_name, connection_object) # Writes to a SQL table\n",
        "df.to_json(filename) # Writes to a file in JSON format\n",
        "df.to_html(filename) # Saves as an HTML table\n",
        "df.to_clipboard() # Writes to the clipboard\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}